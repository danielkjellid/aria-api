#!/usr/bin/env python3
import argparse
import functools
import os
import sys
from datetime import date
from urllib.parse import unquote, urlsplit

from utils.colors import red
from utils.config import PROJECT_ROOT
from utils.decorators import not_in_dev
from utils.executables import run_cli_command, run_postgres_command
from utils.helpers import check_exit_code
from utils.managers import action_runner

AWS_CLI_INSTALL_ERROR_MESSAGE = f"""
{red("Please install the AWS CLI")}
It does not look lik you have a functional installation of AWS CLI.
AWS CLI is used to download the static files, so it needs to be on
the path and authenticated.
"""

AWS_CLI_DOWNLOAD_ERROR_MESSAGE = f"""
{red("Unable to download dump file")}
Please make sure AWS CLI is authenticated. AWS CLI is used to download
the static files. You might need to run aws configure.

Also make sure to have set both AWS_ACCESS_KEY and AWS_SECRET_ACCESS_KEY
in your .envrc. These values can be obtained by an admin.
"""

has_aws_cli = functools.partial(check_exit_code, "aws", "--version")
authenticated_aws_cli = functools.partial(
    check_exit_code, "aws", "sts", "get-caller-identity"
)


def _sanity_checks() -> None:
    if not os.environ.get("AWS_S3_BUCKET_NAME"):
        sys.exit(
            "Error: The AWS_S3_BUCKET_NAME environment variable is not set. "
            "This must be configured before you can download static files"
        )
    if not os.environ.get("DATABASE_URL"):
        sys.exit(
            "Error: The DATABASE_URL environment variable is not set. "
            "This must be configured before you can create dumps"
        )


@not_in_dev
def main() -> None:
    parser = argparse.ArgumentParser(description="Upload db dump to AWS")

    parser.add_argument("--host", help="Host to connect to PostgreSQL on")
    parser.add_argument("--port", type=int, help="Port to connect to PostgreSQL on")
    parser.add_argument("--user", help="User to connect to PostgreSQL with")
    parser.add_argument("--password", help="Password to connect to PostgreSQL with")

    parser.add_argument(
        "--keep-dump",
        action="store_true",
        help="Keep the database dump after uploading to AWS S3",
    )

    args = parser.parse_args()

    # Check that we are in a good state before starting.
    _sanity_checks()

    bucket_name = os.environ.get("AWS_S3_BUCKET_NAME")
    db_url = os.environ.get("DATABASE_URL", None)
    dump_filename = f"aria-{date.today().strftime('%d-%m-%Y')}.dump"
    created_dump_path = PROJECT_ROOT / dump_filename

    if db_url is not None:
        db_config = urlsplit(db_url)
        assert db_config.scheme == "postgresql" or db_config.scheme == "postgres"

        db_name = db_config.path[1:]
        pg_host = db_config.hostname
        pg_user = db_config.username
        pg_port = db_config.port
        pg_password = unquote(db_config.password) if db_config.password else None
    else:
        db_name = "aria"
        pg_host = args.host
        pg_user = args.user
        pg_port = args.port
        pg_password = args.password

    if not has_aws_cli():
        sys.exit(AWS_CLI_INSTALL_ERROR_MESSAGE)

    if not authenticated_aws_cli():
        sys.exit(AWS_CLI_DOWNLOAD_ERROR_MESSAGE)

    with action_runner(description="Creating dump"):
        run_postgres_command(
            "pg_dump",
            "-Fc",
            "--no-acl",
            "--no-owner",
            "--dbname",
            db_name,
            "-f",
            PROJECT_ROOT / dump_filename,
            user=pg_user,
            port=pg_port,
            host=pg_host,
            password=pg_password,
        )

    with action_runner(description="Uploading dump to AWS"):
        run_cli_command(
            "aws",
            "s3",
            "cp",
            created_dump_path,
            f"s3://{bucket_name}/dumps/{dump_filename}",
        )

    if not args.keep_dump:
        with action_runner(description="Removing database dump"):
            run_cli_command("rm", created_dump_path)


if __name__ == "__main__":
    main()
